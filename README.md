ğŸ§  CNN Animations

Animations that explain the building blocks of Convolutional Neural Networks (CNNs), step by step.

ğŸ“Œ Why CNNs?

A Convolutional Neural Network (CNN) is a special kind of deep learning model designed to work with grid-like data such as images or audio spectrograms.

CNNs use three key ideas:

ğŸ” Local receptive fields â€“ small filters (kernels) look at small neighborhoods in the data

â™»ï¸ Weight sharing â€“ the same kernel slides everywhere, reducing parameters

ğŸ— Hierarchy of features â€“ shallow layers learn edges/textures, deeper layers learn shapes/objects

ğŸŒŠ What is a Feature Map?

When you apply a kernel to an input and then pass the result through a nonlinearity (like ReLU), you get a feature map:

It highlights where the filterâ€™s pattern (e.g., vertical edge) appears in the input

Different kernels produce different feature maps (edges, corners, blobs)

Stacking many maps across channels builds a rich representation of the input

Think of feature maps as the â€œeyesâ€ of the CNNâ€”each filter looking for its own pattern.

ğŸ¬ Episode 1 â€” Convolution

In this repo, we start with the most fundamental operation: 2D Convolution.

Input: 5Ã—5 grid

Kernel: 3Ã—3 filter

Padding: valid (no padding)

Stride: 1

At each position, the kernel slides across the input:

Multiply each overlapping pair (input Ã— kernel)

Sum them all â†’ one number

Place that number in the output grid

This produces a 3Ã—3 feature map, which encodes how strongly the kernelâ€™s pattern appears at each location.

ğŸ“œ License

MIT â€” free to use and share